'''

Python web scraper

'''


import csv
import requests
from bs4 import BeautifulSoup




#import xlwt

#pythonWebScrapingGPUS = Workbook()

def csv_table_OverWrite(filename, data):
    """
    Creates a CSV file with the given filename, headers, and data.

    Args:
        filename (str): The name of the CSV file to create.
        headers (list): A list of strings representing the column headers.
        data (list of lists): A list of lists, where each inner list represents a row of data.
    """
    with open(filename, 'w', newline='') as csvfile:
        fieldnames = ['Name', 'Brand', 'Price', 'Availability', 'Reviews', 'Model#']
        writer = csv.DictWriter(csvfile, delimiter='|', fieldnames=fieldnames)
        
        writer.writeheader()
        writer.writerows(data)

#this loop iterates through the each page of the website
url1 = 'https://www.newegg.com/p/pl?N=100006662&PageSize=96&page=1'

pageNumber = 1

#writing object headers to csv filename
filename = 'webscrapingGPUData'
headers = ['Name', 'Brand', 'Price', 'Availability', 'Reviews', 'Model#']
itemDictionary = [ {'Name': 'NULL', 'Brand': 'NULL', 'Price': 'NULL', 'Availability': 'NULL', 'Reviews': 'NULL', 'Model#': 'NULL'} ]

while pageNumber < 20:
    page = requests.get(url1)

    soup = BeautifulSoup(page.text, 'html.parser')
    itemObjects = soup.find_all('div', class_='item-cell')

    for itemObject in itemObjects:
        
        #checks if product is in stock
        try:
            Availability = itemObject.find('p', class_='item-promo').text
        except:
            Availability = 'IN STOCK'
        
        #checks the brand of product
        try:
            brandImage = itemObject.find('a', class_='item-brand').find('img')
            Brand = brandImage['alt']
        except:
            Brand = 'NULL'
        
        #checks the product description
        try:
            Name = ''
            Name += itemObject.find('a', class_='item-title').text
        except:
            Name = 'NULL'
        
        #checks the product price
        try:
            Price = itemObject.find('li', class_='price-current').find('strong').text
        except:
            Price = 'NULL'

        #checks amount of ratings product has   
        try:
            Reviews = itemObject.find('span', class_='item-rating-num').text
        except:
            Reviews = 'NULL'
        
        #checks the model number
        try:
            ModelNum = itemObject.find('ul', class_='item-features').text
        except:
            ModelNum = 'NULL'
        itemDictionary.append( {'Name': Name, 'Brand': Brand, 'Price': Price, 'Availability': Availability, 'Reviews': Reviews, 'Model#': ModelNum} )
    

    
    
    newPage = str(pageNumber)

    if pageNumber >= 11:
        url1 = url1[:-1] + ''
        url1 = url1[:-1] + ''
        url1 += newPage
        print(pageNumber)
        print(url1)
    else:
        url1 = url1[:-1] + newPage
        print(pageNumber)
        print(url1)

    pageNumber += 1
    
    '''
    print(Name)
    print(Brand)
    print(Price)
    print(Availability)
    print(Reviews)
    print(ModelNum)
    '''

csv_table_OverWrite(filename, itemDictionary)
    


    
    
